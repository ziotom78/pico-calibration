#!/bin/bash
#SBATCH --partition=debug
#SBATCH --account=mp107
#SBATCH --nodes=@{nodes}
#SBATCH --time=@{walltime}
#SBATCH --job-name=pico-caltod-creation
#SBATCH --output=pico-caltod-creation_%j.log

set -o errexit
set -v

echo Starting slurm script at $(date)

echo -e "\n-----------------------------------------------------------------------"
echo -e "ENVIRONMENT:\n"
env | sort -d
echo -e "-----------------------------------------------------------------------\n"
echo "PYTHON: $(which python)"
echo "PYTHON VERSION: $(python --version &> /dev/stdout)"
echo ""

outdir=@{outdir_cal}
mkdir -p "${outdir}"

# This script assumes that you are running at NERSC and have already
# loaded the toast module for the correct machine / configuration.
# pico simulations needs to be executed with the 
# https://github.com/zonca/toast/tree/pico_fits branch

nodes=@{nodes}

# How many processes are we running per node?  Handle
# the case of a very small simulation.
if [ $nodes -lt 5 ]; then
    node_proc=1
else
    node_proc=8
fi

# Generate the focalplane file if it does not already exist.

detpix=1

fpfile="${outdir}/fp_${detpix}.pkl"
if [ ! -e "${fpfile}" ]; then
    echo "Running toast_fake_focalplane.py..."
    srun -n 1 -N 1 toast_fake_focalplane.py \
        --bandcenter_ghz 89.6 \
        --bandwidth_ghz 22.4 \
        --fwhm 9.5 \
        --psd_NET @{psd_NET} \
        --psd_fknee @{fknee_Hz} \
        --psd_alpha 1 \
        --psd_fmin 1.0e-5 \
        --disable-timer-serialization \
        --toast-output-dir "${outdir}" \
        --toast-timing-fname "timing_report_fp" \
        --minpix ${detpix} --out "${outdir}/fp"
fi

gain2toast=@{code_path}/gain2toast.py
echo "Running ${gain2toast}"

python ${gain2toast} @{gain2toast_input} @{gain2toast_output}

# The executable script

ex=$(which toast_satellite_sim.py)
echo "Using ${ex}"

# Observations

nobs=365

groupnodes=0

# Data distribution parameters.  We are distributing by detector,
# so if our number of processes in a group is larger than the number
# of detectors this is bad.  In that case, set the group size to 
# one, so we have many more groups, each assigned

groupsize=1

madam="@{code_path}/pico_madam.par"

# The commandline

com="${ex} \
    --samplerate @{sample_rate} \
    --spinperiod @{spin_period_min} \
    --spinangle @{spin_angle_deg} \
    --precperiod @{prec_period_min} \
    --precangle @{prec_angle_deg} \
    --hwprpm 0.0 \
    --baseline @{baseline_length_s} \
    --nside 512 \
    --obs 24.0 \
    --apply_beam \
    --flush \
    --gain @{gain2toast_output} \
    --input_dipole solar \
    --input_dipole_solar_speed_kms 370.0822332 \
    --input_dipole_solar_gal_lat_deg 48.24 \
    --input_dipole_solar_gal_lon_deg 264.00 \
    --input_pysm_model c1 \
    --input_pysm_precomputed_cmb /global/cscratch1/sd/zonca/pico/cal_sims/pico_cmb_nodip.fits \
    --toast-output-dir "${outdir}" \
    --toast-timing-fname "timing_report_main" \
    --groupsize ${groupsize} \
    --debug \
    --madam \
    --madampar ${madam} \
    --fp ${fpfile} \
    --numobs ${nobs} \
    --outdir ${outdir}/out \
    $@@ \
"

#--- Hardware configuration ----

# Hyperthread CPUs per physical core
cpu_per_core=2

# Physical cores we are using
node_cores=24

node_thread=$(( node_cores / node_proc ))
node_depth=$(( cpu_per_core * node_thread ))
procs=$(( nodes * node_proc ))

export OMP_NUM_THREADS=${node_thread}
export OMP_PLACES=threads
export OMP_PROC_BIND=spread
export TOAST_NODE_COUNT=${nodes}
export TOAST_NUM_THREADS=${OMP_NUM_THREADS}
echo "OpenMP # threads: ${OMP_NUM_THREADS}"
echo "TOAST # threads: ${TOAST_NUM_THREADS}"

# Set TMPDIR to be on the ramdisk
export TMPDIR=/dev/shm

run="srun --cpu_bind=cores -n ${procs} -N ${nodes} -c ${node_depth}"

echo Calling srun at $(date)

: ${LOG_OUT:="${outdir}/log"}
echo "${run} ${com}"
eval ${run} ${com} > ${LOG_OUT} 2>&1

echo End slurm script at $(date)
